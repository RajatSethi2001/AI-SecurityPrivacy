{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 64)   55552       input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 64)   55552       input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   55552       input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 3)    0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16, 16, 195)  0           conv2d_10[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 49920)        0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          25559552    flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 10)           5130        dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 25,731,338\n",
      "Trainable params: 25,731,338\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/24\n",
      "157/157 [==============================] - 60s 381ms/step - loss: 1.8508 - accuracy: 0.3347 - val_loss: 1.6574 - val_accuracy: 0.4071\n",
      "Epoch 2/24\n",
      "157/157 [==============================] - 60s 382ms/step - loss: 1.5658 - accuracy: 0.4392 - val_loss: 1.5659 - val_accuracy: 0.4324\n",
      "Epoch 3/24\n",
      "157/157 [==============================] - 60s 383ms/step - loss: 1.4641 - accuracy: 0.4755 - val_loss: 1.4681 - val_accuracy: 0.4765\n",
      "Epoch 4/24\n",
      "157/157 [==============================] - 60s 380ms/step - loss: 1.3869 - accuracy: 0.5073 - val_loss: 1.4803 - val_accuracy: 0.4860\n",
      "Epoch 5/24\n",
      "157/157 [==============================] - 60s 380ms/step - loss: 1.3235 - accuracy: 0.5275 - val_loss: 1.4115 - val_accuracy: 0.5024\n",
      "Epoch 6/24\n",
      "157/157 [==============================] - 60s 380ms/step - loss: 1.2577 - accuracy: 0.5556 - val_loss: 1.3450 - val_accuracy: 0.5243\n",
      "Epoch 7/24\n",
      "157/157 [==============================] - 60s 382ms/step - loss: 1.1897 - accuracy: 0.5781 - val_loss: 1.3561 - val_accuracy: 0.5319\n",
      "Epoch 8/24\n",
      "157/157 [==============================] - 60s 383ms/step - loss: 1.1307 - accuracy: 0.5989 - val_loss: 1.3158 - val_accuracy: 0.5392\n",
      "Epoch 9/24\n",
      "157/157 [==============================] - 60s 384ms/step - loss: 1.0780 - accuracy: 0.6189 - val_loss: 1.2761 - val_accuracy: 0.5576\n",
      "Epoch 10/24\n",
      "157/157 [==============================] - 60s 382ms/step - loss: 1.0162 - accuracy: 0.6428 - val_loss: 1.3066 - val_accuracy: 0.5485\n",
      "Epoch 11/24\n",
      "157/157 [==============================] - 60s 382ms/step - loss: 0.9676 - accuracy: 0.6572 - val_loss: 1.2421 - val_accuracy: 0.5794\n",
      "Epoch 12/24\n",
      "157/157 [==============================] - 60s 384ms/step - loss: 0.8999 - accuracy: 0.6838 - val_loss: 1.2674 - val_accuracy: 0.5754\n",
      "Epoch 13/24\n",
      "157/157 [==============================] - 60s 384ms/step - loss: 0.8443 - accuracy: 0.7050 - val_loss: 1.3482 - val_accuracy: 0.5534\n",
      "Epoch 14/24\n",
      "157/157 [==============================] - 60s 383ms/step - loss: 0.7958 - accuracy: 0.7197 - val_loss: 1.2717 - val_accuracy: 0.5824\n",
      "Epoch 15/24\n",
      "157/157 [==============================] - 60s 383ms/step - loss: 0.7211 - accuracy: 0.7496 - val_loss: 1.3267 - val_accuracy: 0.5813\n",
      "Epoch 16/24\n",
      "157/157 [==============================] - 60s 383ms/step - loss: 0.6719 - accuracy: 0.7649 - val_loss: 1.3923 - val_accuracy: 0.5620\n",
      "Epoch 17/24\n",
      "157/157 [==============================] - 60s 383ms/step - loss: 0.6106 - accuracy: 0.7883 - val_loss: 1.3550 - val_accuracy: 0.5808\n",
      "Epoch 18/24\n",
      "157/157 [==============================] - 60s 382ms/step - loss: 0.5509 - accuracy: 0.8112 - val_loss: 1.5009 - val_accuracy: 0.5583\n",
      "Epoch 19/24\n",
      "157/157 [==============================] - 60s 382ms/step - loss: 0.4842 - accuracy: 0.8351 - val_loss: 1.5015 - val_accuracy: 0.5758\n",
      "Epoch 20/24\n",
      "157/157 [==============================] - 60s 383ms/step - loss: 0.4177 - accuracy: 0.8611 - val_loss: 1.4773 - val_accuracy: 0.5892\n",
      "Epoch 21/24\n",
      "157/157 [==============================] - 60s 382ms/step - loss: 0.3780 - accuracy: 0.8726 - val_loss: 1.5724 - val_accuracy: 0.5809\n",
      "Epoch 22/24\n",
      "157/157 [==============================] - 62s 392ms/step - loss: 0.3260 - accuracy: 0.8928 - val_loss: 1.6012 - val_accuracy: 0.5797\n",
      "Epoch 23/24\n",
      "157/157 [==============================] - 63s 402ms/step - loss: 0.2715 - accuracy: 0.9147 - val_loss: 1.6643 - val_accuracy: 0.5826\n",
      "Epoch 24/24\n",
      "157/157 [==============================] - 63s 400ms/step - loss: 0.2276 - accuracy: 0.9314 - val_loss: 1.7711 - val_accuracy: 0.5852\n",
      "[0.5048223733901978, 0.8729400038719177]\n",
      "[1.79445219039917, 0.5687999725341797]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Input, Dense, Activation, Conv2D, MaxPooling2D, Flatten, Concatenate\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "Conv2D_1_Filters = 64\n",
    "Conv2D_1_KernelSize = (17, 17)\n",
    "Conv2D_1_Activation = \"relu\"\n",
    "\n",
    "Conv2D_2_Filters = 64\n",
    "Conv2D_2_KernelSize = (17, 17)\n",
    "Conv2D_2_Activation = \"relu\"\n",
    "\n",
    "Conv2D_3_Filters = 64\n",
    "Conv2D_3_KernelSize = (17, 17)\n",
    "Conv2D_3_Activation = \"relu\"\n",
    "\n",
    "MaxPool_Size = (2, 2)\n",
    "\n",
    "Dense1_Units = 512\n",
    "Dense1_Activation = \"relu\"\n",
    "\n",
    "Dense2_Units = 10\n",
    "Dense2_Activation = \"softmax\"\n",
    "\n",
    "LearningRate = 0.01\n",
    "Decay = 0.00001\n",
    "Momentum = 0.9\n",
    "\n",
    "Epochs = 24\n",
    "BatchSize = 256\n",
    "ValidationSplit = 0.2\n",
    "\n",
    "params = [f\"Conv2D_1: {Conv2D_1_Filters}, {Conv2D_1_KernelSize}, {Conv2D_1_Activation}\",\n",
    "          f\"Conv2D_1: {Conv2D_2_Filters}, {Conv2D_2_KernelSize}, {Conv2D_2_Activation}\",\n",
    "          f\"Conv2D_1: {Conv2D_3_Filters}, {Conv2D_3_KernelSize}, {Conv2D_3_Activation}\",\n",
    "          f\"MaxPooling2D: {MaxPool_Size}\",\n",
    "          f\"Concatenate - Conv2D_1, Conv2D_2, Conv2D_3, MaxPool\",\n",
    "          f\"Flatten - No Params\",\n",
    "          f\"Dense1: {Dense1_Units}, {Dense1_Activation}\",\n",
    "          f\"Dense2: {Dense2_Units}, {Dense2_Activation}\",\n",
    "          f\"Learning Rate: {LearningRate}\",\n",
    "          f\"Decay: {Decay}\",\n",
    "          f\"Momentum: {Momentum}\",\n",
    "          f\"Epochs: {Epochs}\",\n",
    "          f\"Batch Size: {BatchSize}\",\n",
    "          f\"Validation Split: {ValidationSplit}\"]\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "#x_train = np.reshape(x_train,(50000,32*32*3))\n",
    "#x_test = np.reshape(x_test,(10000,32*32*3))\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "input_layer = Input(shape=(32,32,3), name=\"input\")\n",
    "convLayer1 = Conv2D(Conv2D_1_Filters, Conv2D_1_KernelSize, activation=Conv2D_1_Activation)(input_layer)\n",
    "convLayer2 = Conv2D(Conv2D_2_Filters, Conv2D_2_KernelSize, activation=Conv2D_2_Activation)(input_layer)\n",
    "convLayer3 = Conv2D(Conv2D_3_Filters, Conv2D_3_KernelSize, activation=Conv2D_3_Activation)(input_layer)\n",
    "maxPoolLayer = MaxPooling2D(pool_size=MaxPool_Size)(input_layer)\n",
    "concatenateLayer = Concatenate()([convLayer1, convLayer2, convLayer3, maxPoolLayer])\n",
    "flattenLayer = Flatten()(concatenateLayer)\n",
    "denseLayer1 = Dense(Dense1_Units, activation=Dense1_Activation)(flattenLayer)\n",
    "denseLayer2 = Dense(Dense2_Units, activation=Dense2_Activation, name=\"output\")(denseLayer1)\n",
    "model = tf.keras.Model(inputs=[input_layer], outputs=[denseLayer2])\n",
    "\n",
    "mySGD = SGD(learning_rate=LearningRate, decay=Decay, momentum=Momentum)\n",
    "model.compile(optimizer=mySGD, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit({\"input\": x_train}, {\"output\": y_train}, epochs=Epochs, batch_size=BatchSize, validation_split=ValidationSplit)\n",
    "\n",
    "training_score = model.evaluate(x_train, y_train, verbose=0)\n",
    "test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(training_score)\n",
    "print(test_score)\n",
    "\n",
    "currentTime = datetime.now()\n",
    "timeStr = currentTime.strftime(\"%m-%d-%Y_%H:%M:%S\")\n",
    "\n",
    "logFile = open(f\"Model3_History_{timeStr}.txt\", \"w+\")\n",
    "\n",
    "logFile.write(\"Parameters:\\n\")\n",
    "for s in params:\n",
    "    logFile.write(f\"{s}\\n\")\n",
    "logFile.write(\"=================================================\\n\")\n",
    "\n",
    "for e in range(Epochs):\n",
    "    logFile.write(f\"Epoch: {e+1}/{Epochs} - \")\n",
    "    for key in history.history.keys():\n",
    "        logFile.write(f\"{key}: {round(history.history[key][e], 4)} - \")\n",
    "    logFile.write(\"\\n\")\n",
    "    \n",
    "logFile.write(\"=================================================\\n\")\n",
    "logFile.write(\"[Loss, Accuracy]\\n\")\n",
    "logFile.write(f\"Training Score = {training_score}\\n\")\n",
    "logFile.write(f\"Test Score = {test_score}\\n\")\n",
    "logFile.close()\n",
    "model.save(f\"Model3_{timeStr}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "#Change X_Test and Y_Test for a different data set.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "x_test = np.reshape(x_test,(10000,32*32*3))\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "testModel = load_model('FINAL_MODEL3.h5')\n",
    "predictions = testModel.predict(x_test)\n",
    "predictionClass = []\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    imagePrediction = np.where(predictions[i] == predictions[i].max())\n",
    "    predictionClass.append(classes[int(imagePrediction[0])])\n",
    "\n",
    "print(predictionClass)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
