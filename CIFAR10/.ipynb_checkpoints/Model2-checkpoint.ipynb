{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 14400)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               7373312   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 7,380,234\n",
      "Trainable params: 7,380,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/28\n",
      "157/157 [==============================] - 22s 136ms/step - loss: 1.9217 - accuracy: 0.3172 - val_loss: 1.7869 - val_accuracy: 0.3444\n",
      "Epoch 2/28\n",
      "157/157 [==============================] - 21s 136ms/step - loss: 1.5490 - accuracy: 0.4532 - val_loss: 1.4807 - val_accuracy: 0.4847\n",
      "Epoch 3/28\n",
      "157/157 [==============================] - 21s 135ms/step - loss: 1.3497 - accuracy: 0.5215 - val_loss: 1.3365 - val_accuracy: 0.5311\n",
      "Epoch 4/28\n",
      "157/157 [==============================] - 21s 137ms/step - loss: 1.2343 - accuracy: 0.5648 - val_loss: 1.3216 - val_accuracy: 0.5348\n",
      "Epoch 5/28\n",
      "157/157 [==============================] - 22s 139ms/step - loss: 1.1590 - accuracy: 0.5935 - val_loss: 1.1938 - val_accuracy: 0.5858\n",
      "Epoch 6/28\n",
      "157/157 [==============================] - 21s 137ms/step - loss: 1.0792 - accuracy: 0.6244 - val_loss: 1.1671 - val_accuracy: 0.5959\n",
      "Epoch 7/28\n",
      "157/157 [==============================] - 21s 137ms/step - loss: 1.0268 - accuracy: 0.6445 - val_loss: 1.1400 - val_accuracy: 0.6053\n",
      "Epoch 8/28\n",
      "157/157 [==============================] - 22s 137ms/step - loss: 0.9534 - accuracy: 0.6719 - val_loss: 1.0753 - val_accuracy: 0.6262\n",
      "Epoch 9/28\n",
      "157/157 [==============================] - 22s 137ms/step - loss: 0.8948 - accuracy: 0.6898 - val_loss: 1.0672 - val_accuracy: 0.6298\n",
      "Epoch 10/28\n",
      "157/157 [==============================] - 22s 141ms/step - loss: 0.8404 - accuracy: 0.7088 - val_loss: 1.0638 - val_accuracy: 0.6327\n",
      "Epoch 11/28\n",
      "157/157 [==============================] - 22s 138ms/step - loss: 0.7768 - accuracy: 0.7358 - val_loss: 1.0308 - val_accuracy: 0.6453\n",
      "Epoch 12/28\n",
      "157/157 [==============================] - 21s 137ms/step - loss: 0.7153 - accuracy: 0.7577 - val_loss: 0.9983 - val_accuracy: 0.6578\n",
      "Epoch 13/28\n",
      "157/157 [==============================] - 22s 141ms/step - loss: 0.6482 - accuracy: 0.7826 - val_loss: 0.9813 - val_accuracy: 0.6638\n",
      "Epoch 14/28\n",
      "157/157 [==============================] - 22s 140ms/step - loss: 0.5967 - accuracy: 0.8015 - val_loss: 0.9820 - val_accuracy: 0.6725\n",
      "Epoch 15/28\n",
      "157/157 [==============================] - 22s 139ms/step - loss: 0.5260 - accuracy: 0.8293 - val_loss: 1.0069 - val_accuracy: 0.6666\n",
      "Epoch 16/28\n",
      "157/157 [==============================] - 22s 140ms/step - loss: 0.4742 - accuracy: 0.8481 - val_loss: 0.9878 - val_accuracy: 0.6769\n",
      "Epoch 17/28\n",
      "157/157 [==============================] - 22s 141ms/step - loss: 0.4099 - accuracy: 0.8719 - val_loss: 0.9988 - val_accuracy: 0.6784\n",
      "Epoch 18/28\n",
      "157/157 [==============================] - 22s 140ms/step - loss: 0.3620 - accuracy: 0.8913 - val_loss: 1.0540 - val_accuracy: 0.6704\n",
      "Epoch 19/28\n",
      "157/157 [==============================] - 22s 140ms/step - loss: 0.3109 - accuracy: 0.9110 - val_loss: 1.0634 - val_accuracy: 0.6728\n",
      "Epoch 20/28\n",
      "157/157 [==============================] - 22s 140ms/step - loss: 0.2647 - accuracy: 0.9280 - val_loss: 1.1152 - val_accuracy: 0.6700\n",
      "Epoch 21/28\n",
      "157/157 [==============================] - 22s 140ms/step - loss: 0.2261 - accuracy: 0.9418 - val_loss: 1.0986 - val_accuracy: 0.6735\n",
      "Epoch 22/28\n",
      "157/157 [==============================] - 22s 141ms/step - loss: 0.1797 - accuracy: 0.9601 - val_loss: 1.1294 - val_accuracy: 0.6771\n",
      "Epoch 23/28\n",
      "157/157 [==============================] - 22s 140ms/step - loss: 0.1472 - accuracy: 0.9716 - val_loss: 1.1703 - val_accuracy: 0.6715\n",
      "Epoch 24/28\n",
      "157/157 [==============================] - 22s 139ms/step - loss: 0.1225 - accuracy: 0.9779 - val_loss: 1.2320 - val_accuracy: 0.6705\n",
      "Epoch 25/28\n",
      "157/157 [==============================] - 22s 138ms/step - loss: 0.0993 - accuracy: 0.9860 - val_loss: 1.2481 - val_accuracy: 0.6698\n",
      "Epoch 26/28\n",
      "157/157 [==============================] - 22s 140ms/step - loss: 0.0811 - accuracy: 0.9895 - val_loss: 1.2107 - val_accuracy: 0.6862\n",
      "Epoch 27/28\n",
      "157/157 [==============================] - 21s 136ms/step - loss: 0.0644 - accuracy: 0.9941 - val_loss: 1.2305 - val_accuracy: 0.6833\n",
      "Epoch 28/28\n",
      "157/157 [==============================] - 22s 138ms/step - loss: 0.0555 - accuracy: 0.9952 - val_loss: 1.2584 - val_accuracy: 0.6882\n",
      "[0.28868231177330017, 0.935479998588562]\n",
      "[1.280212640762329, 0.6743999719619751]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Activation, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "Conv2D_Filters = 64\n",
    "Conv2D_KernelSize = (3, 3)\n",
    "Conv2D_Activation = \"relu\"\n",
    "\n",
    "MaxPool_Size = (2, 2)\n",
    "\n",
    "Dense1_Units = 512\n",
    "Dense1_Activation = \"relu\"\n",
    "\n",
    "Dense2_Units = 10\n",
    "Dense2_Activation = \"softmax\"\n",
    "\n",
    "LearningRate = 0.01\n",
    "Decay = 0.00001\n",
    "Momentum = 0.9\n",
    "\n",
    "Epochs = 28\n",
    "BatchSize = 256\n",
    "ValidationSplit = 0.2\n",
    "\n",
    "params = [f\"Conv2D: {Conv2D_Filters}, {Conv2D_KernelSize}, {Conv2D_Activation}\",\n",
    "          f\"MaxPooling2D: {MaxPool_Size}\",\n",
    "          f\"Flatten - No Params\",\n",
    "          f\"Dense1: {Dense1_Units}, {Dense1_Activation}\",\n",
    "          f\"Dense2: {Dense2_Units}, {Dense2_Activation}\",\n",
    "          f\"Learning Rate: {LearningRate}\",\n",
    "          f\"Decay: {Decay}\",\n",
    "          f\"Momentum: {Momentum}\",\n",
    "          f\"Epochs: {Epochs}\",\n",
    "          f\"Batch Size: {BatchSize}\",\n",
    "          f\"Validation Split: {ValidationSplit}\"]\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "#x_train = np.reshape(x_train,(50000,32*32*3))\n",
    "#x_test = np.reshape(x_test,(10000,32*32*3))\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(32,32,3)))\n",
    "model.add(Conv2D(Conv2D_Filters, Conv2D_KernelSize, activation=Conv2D_Activation))\n",
    "model.add(MaxPooling2D(pool_size=MaxPool_Size))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(Dense1_Units, activation=Dense1_Activation))\n",
    "model.add(Dense(Dense2_Units, activation=Dense2_Activation))\n",
    "mySGD = SGD(learning_rate=LearningRate, decay=Decay, momentum=Momentum)\n",
    "\n",
    "model.compile(optimizer=mySGD, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=Epochs, batch_size=BatchSize, validation_split=ValidationSplit)\n",
    "\n",
    "training_score = model.evaluate(x_train, y_train, verbose=0)\n",
    "test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(training_score)\n",
    "print(test_score)\n",
    "\n",
    "currentTime = datetime.now()\n",
    "timeStr = currentTime.strftime(\"%m-%d-%Y_%H:%M:%S\")\n",
    "\n",
    "logFile = open(f\"Model2_History_{timeStr}.txt\", \"w+\")\n",
    "\n",
    "logFile.write(\"Parameters:\\n\")\n",
    "for s in params:\n",
    "    logFile.write(f\"{s}\\n\")\n",
    "logFile.write(\"=================================================\\n\")\n",
    "\n",
    "for e in range(Epochs):\n",
    "    logFile.write(f\"Epoch: {e+1}/{Epochs} - \")\n",
    "    for key in history.history.keys():\n",
    "        logFile.write(f\"{key}: {round(history.history[key][e], 4)} - \")\n",
    "    logFile.write(\"\\n\")\n",
    "    \n",
    "logFile.write(\"=================================================\\n\")\n",
    "logFile.write(\"[Loss, Accuracy]\\n\")\n",
    "logFile.write(f\"Training Score = {training_score}\\n\")\n",
    "logFile.write(f\"Test Score = {test_score}\\n\")\n",
    "logFile.close()\n",
    "model.save(f\"Model2_{timeStr}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "#Change X_Test and Y_Test for a different data set.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "x_test = np.reshape(x_test,(10000,32*32*3))\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "testModel = load_model('FINAL_MODEL2.h5')\n",
    "predictions = testModel.predict(x_test)\n",
    "predictionClass = []\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    imagePrediction = np.where(predictions[i] == predictions[i].max())\n",
    "    predictionClass.append(classes[int(imagePrediction[0])])\n",
    "\n",
    "print(predictionClass)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
